#!/usr/bin/env python3

import apprentice as app
import numpy as np
import time
import os
import sys

def mkPlotsMinimum(TO, x0, y0=None, prefix=""):
    temp = TO._fixIdx
    import pylab
    pnames = np.array(TO.pnames)[TO._freeIdx]

    XX = [TO.lineScan(x0,i) for i in range(len(x0))]
    YY = []
    for i, X in enumerate(XX):
        Y   =[TO.objective(x) for x in X]
        YY.append(Y)
        Y   =[TO.objective(x, unbiased=True) for x in X]
        YY.append(Y)
    ymax=np.max(np.array(YY))
    ymin=np.min(np.array(YY))


    for i in range(len(x0)):
        pylab.clf()
        X=TO.lineScan(x0,i)
        Y   =[TO.objective(x) for x in X]
        Yunb=[TO.objective(x, unbiased=True) for x in X]
        pylab.axvline(x0[i], label="x0=%.5f"%x0[i], color="k")
        y0=TO.objective(x0, unbiased=True)
        # pylab.axhline(y0, label="unbiased y0=%.2f"%y0, color="k")
        pylab.plot(X[:,i], Y, label="objective")
        # pylab.plot(X[:,i], Yunb, linestyle="dashed", label="unbiased")
        #TODO just normalized ratio of bias vs unbiased
        pylab.ylabel("objective")
        pylab.xlabel(pnames[i])
        pylab.ylim((0.9*ymin, 1.1*ymax))
        # if abs(ymin-ymax)>1000:
            # pylab.yscale("log")
        pylab.legend()
        pylab.tight_layout()
        pylab.savefig(prefix+"valley_{}.pdf".format(i))

def mkPlotsCorrelation(TO, x0, prefix=""):
    H=TO.hessian(x0)
    COV = np.linalg.inv(H)
    COR = np.zeros_like(COV)
    nd = len(x0)
    for i in range(nd):
        for j in range(nd):
            COR[i,j] = COV[i,j]/np.sqrt(COV[i,i]*COV[j,j])

    mask =  np.tri(COR.shape[0], k=0)
    A = np.ma.array(COR, mask=mask)
    import pylab
    pylab.clf()
    bb = pylab.imshow(A, vmin=-1, vmax=1, cmap="RdBu")
    locs, labels = pylab.yticks()
    pylab.yticks([i for i in range(nd)], TO.pnames, rotation=00)
    locs, labels = pylab.xticks()
    pylab.xticks([i for i in range(nd)], TO.pnames, rotation=90)
    cbar = pylab.colorbar(bb, extend='both')

    pylab.tight_layout()
    pylab.savefig(prefix+"corr.pdf")

def mkPlotsWeights(old_weights_file, new_weights_file, prefix=""):
    def read_weights(path):
        weights = {}
        try:
            with open(path, 'r') as f:
                for line in f:
                    s = line.strip()
                    if not s or s.startswith('#'):
                        continue
                    parts = s.split(None, 2)
                    if len(parts) < 2:
                        continue
                    if len(parts[0].split('#')) > 1:
                        continue
                    obs, val = parts[0], parts[1]
                    try:
                        w = float(val)
                    except ValueError:
                        continue
                    weights[obs] = w
        except FileNotFoundError:
            weights = {}
        return weights

    w_old = read_weights(old_weights_file)
    w_new = read_weights(new_weights_file)
    seen = set(w_old)
    obs_list = list(w_old) + [o for o in w_new if o not in seen]
    if not obs_list:
        return
    old_vals = [w_old.get(o, 0.0) for o in obs_list]
    new_vals = [w_new.get(o, 0.0) for o in obs_list]

    import pylab
    N = len(obs_list)
    ind = np.arange(N)
    jitter = 0.05
    pylab.figure(figsize=(max(8, N * 0.22), 6))
    pylab.plot(ind - jitter, old_vals, linestyle='None', marker='o', markersize=5, label='old', color="cornflowerblue")
    pylab.plot(ind + jitter, new_vals, linestyle='None', marker='s', markersize=5, label='new', color="coral")
    pylab.xticks(ind, obs_list, rotation=90)
    pylab.ylabel('weight')
    pylab.title('Weights comparison')
    pylab.legend()
    pylab.tight_layout()
    pylab.savefig(prefix + 'weights_comparison.pdf', dpi=200)

import optparse, os, sys
op = optparse.OptionParser(usage=__doc__)
op.add_option("-v", "--debug", dest="DEBUG", action="store_true", default=False, help="Turn on some debug messages")
op.add_option("-o", dest="OUTDIR", default="tune", help="Output directory (default: %default)")
op.add_option("-e", "--errorapprox", dest="ERRAPP", default=None, help="Approximations of bin uncertainties (default: %default)")
op.add_option("-s", "--survey", dest="SURVEY", default=1, type=int, help="Size of survey when determining start point (default: %default)")
op.add_option("-r", "--restart", dest="RESTART", default=1, type=int, help="Minimiser restarts (default: %default)")
op.add_option("--seed", dest="SEED", default=1234, type=int, help="The base random seed (default: %default)")
op.add_option("--msp", dest="MSP", default=None, help="Manual startpoint, comma separated string (default: %default)")
op.add_option("-a", "--algorithm", dest="ALG", default="tnc", help="The minimisation algrithm tnc, ncg, lbfgsb, trust (default: %default)")
op.add_option("-l", "--limits", dest="LIMITS", default=None, help="Parameter file with limits and fixed parameters (default: %default)")
op.add_option("-f", dest="FORCE", default=False, action = 'store_true', help="Allow overwriting output directory (default: %default)")
op.add_option("-p", "--plotvalley", dest="PLOTVALLEY", default=False, action = 'store_true', help="Allow overwriting output directory (default: %default)")
op.add_option("--tol", dest="TOL", default=1e-6, type=float, help="Tolerance for scipy optimize minimize (default: %default)")
op.add_option("--no-check", dest="NOCHECK", default=False, action="store_true", help="Don't check for sadlepoints (default: %default)")

op.add_option("--objective", dest="OBJECTIVE", choices=["portfolio", "score-mean", "score-median"], default="portfolio", help="Objective function to use for bilevel optimization (default: %default)")
op.add_option("--lambda-var", dest="LAMBDA", type="float", default=1.0, help="Regularization parameter for bilevel optimization with portfolio (default: %default)")
op.add_option("--n-0", dest="N_0", type=int, default=10, help="Number of initial points for bilevel optimization, n_0 > number of observables (default: %default)")
op.add_option("--n-max", dest="N_MAX", type=int, default=20, help="Maximum number of points for bilevel optimization, n_max > n_0 (default: %default)")
op.add_option("--surrogate", dest="SURROGATE", default=False, action="store_true", help="Enable surrogate model for bilevel optimization (default: %default)")
op.add_option("--load-surrogate", dest="LOAD_SURROGATE", default=None, metavar="FILE", help="Load pre-trained surrogate model from FILE. Automatically enables surrogate mode (default: None)")
op.add_option("--candidates", dest="CANDIDATES", type=int, default=1000, help="Number of candidates for bilevel optimization (default: %default)")
op.add_option("--exploration", dest="EXPLORATION", type=float, default=(0.3, 0.5, 0.7), help="Exploration parameter for bilevel optimization (default: %default)")

opts, args = op.parse_args()


if opts.ALG not in ["tnc", "ncg", "lbfgsb" ,"trust"]:
    raise Exception("Minimisation algorithm {} not implemented, should be tnc, ncg, lbfgsb or trust, exiting".format(opts.ALG))

#TODO add protections and checks if files exist etc
if not os.path.exists(opts.OUTDIR): os.makedirs(opts.OUTDIR)

WFILE = args[0]
DATA  = args[1]
APP   = args[2]

np.random.seed(opts.SEED)

GOF = app.appset.TuningObjective2(WFILE, DATA, APP, f_errors=opts.ERRAPP, debug=opts.DEBUG)
if opts.LIMITS is not None: GOF.setLimitsAndFixed(opts.LIMITS)

if opts.MSP is not None:
    x0 = [float(x) for x in opts.MSP.split(",")]
    GOF.setManualStartPoint(x0)

BO = app.bilevel.BilevelObjective(GOF, objective=opts.OBJECTIVE, lambda_var=opts.LAMBDA)

surrogate_enabled = opts.SURROGATE
if opts.LOAD_SURROGATE is not None:
    if os.path.exists(opts.LOAD_SURROGATE):
        success = BO.loadSurrogateModel(opts.LOAD_SURROGATE)
        if success:
            surrogate_enabled = True
        else:
            print(f"Warning: Failed to load surrogate model from {opts.LOAD_SURROGATE}")
    else:
        print(f"Warning: Surrogate file {opts.LOAD_SURROGATE} not found")

import time
t0=time.time()
best = BO.optimize(n_0=opts.N_0, n_max=opts.N_MAX, survey_inner=opts.SURVEY, restart_inner=opts.RESTART, surrogate=surrogate_enabled, candidates=opts.CANDIDATES, exploration=opts.EXPLORATION, debug=opts.DEBUG)
res = best.res

t1=time.time()
if opts.DEBUG: print(best)

chi2 = GOF.objective(res.x, unbiased=True)
ndf = GOF.ndf

meta  = "# Objective value at best fit point: %.2f (%.2f without weights)\n"%(res.fun, chi2)
meta += "# Degrees of freedom: {}\n".format(ndf)
meta += "# phi2/ndf: %.3f\n"%(chi2/ndf)
meta += "# Minimisation took {} seconds\n".format(t1-t0)
meta += "# Command line: {}\n".format(" ".join(sys.argv))
meta += "# Best fit point:"

print(meta)
print(GOF.printParams(res.x))

outcommon = "{}_{}_{}".format(opts.ALG, opts.SURVEY, opts.RESTART, opts.SEED)

try:
    import yoda
    app.tools.prediction2YODA(APP, GOF.mkPoint(res.x), opts.OUTDIR+"/predictions_{}.yoda".format(outcommon), opts.ERRAPP)
except ImportError:
    pass

mkPlotsCorrelation(GOF, res.x, opts.OUTDIR+"/{}_".format(outcommon))
GOF.writeResult(res.x, os.path.join(opts.OUTDIR, "minimum_{}.txt".format(outcommon)), meta=meta)
if opts.PLOTVALLEY:
    plotout = os.path.join(opts.OUTDIR, "valleys_{}".format(outcommon))
    if not os.path.exists(plotout): os.makedirs(plotout)
    mkPlotsMinimum(GOF, res.x, prefix=plotout+"/")

BO.writeResults(WFILE, opts.OUTDIR)
mkPlotsWeights(WFILE, os.path.join(opts.OUTDIR, 'best_weights.txt'), prefix=os.path.join(opts.OUTDIR, ''))

import shutil
shutil.copy(WFILE, os.path.join(opts.OUTDIR, "weights_{}.txt".format(outcommon)))

print("Output written to directory {}.".format(opts.OUTDIR))